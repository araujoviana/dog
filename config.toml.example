[auth]
api_key                  = ""  # Groq API key

[paths]
audio_folder              = "input-data"         # Folder for raw audio files
docs_folder               = "input-data"         # Folder for raw text files
preprocessed_audio_folder = "preprocessed_audio" # Folder for preprocessed audio
output_folder             = "processed-audio"    # Folder for processed audio
log_folder                = "log"                # Folder for logs
transcription_folder      = "transcripted-audio" # Folder for transcripts
cleaned_folder            = "cleaned-text"       # Folder for cleaned text outputs

[audio]
model                    = "small"               # Whisper flavor for audio transcription

[ocr_settings]
language = "por"  # Tesseract language code

[clean_up]
model             = "meta-llama/llama-4-maverick-17b-128e-instruct"  # LLM used for text cleaning
api_call_cooldown = 5                                                # Seconds between API calls
chunk_size        = 8000                                           # Max characters per API call for cleaning
audio_prompt      = """
INSTRUÇÃO:
Você é um limpador de transcrições de áudio. Corrija erros, normalize formatação e preserve termos técnicos.
TEXTO DE ENTRADA:
{text_chunk}



TEXTO LIMPO EM MARKDOWN:
"""  # Prompt for cleaning audio transcripts

text_prompt = """
INSTRUÇÃO:
Você organiza e limpa textos. Corrija erros, formate em markdown e use blocos KaTeX para fórmulas.
Texto para processar:
{text_chunk}
"""  # Prompt for general text cleaning

[embedding]
embedding_model          = "all-MiniLM-L6-v2"
cross_encoder            = "cross-encoder/ms-marco-MiniLM-L-12-v2"
chunk_size               = 512  # Character count, not tokens
overlap                  = 100  # Character count
candidates_to_retrieve   = 25   # Number of chunks to get from vector store before reranking
final_chunks_to_use      = 5    # Number of chunks to use after reranking

["retrieval"]
model                    = "openai/gpt-oss-120b"  # Model for final answer generation
prompt                   = """
Você é um assistente de IA. Use apenas o contexto abaixo para responder à pergunta.
CONTEXTOS:
{context}

PERGUNTA:
{query}

RESPOSTA:
"""  # Prompt template for RAG retrieval answers
temperature              = 0.2
top_p                    = 0.9
